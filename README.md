### Abstract

Multi Head Latent Attention Uses SVD for matrix compression. Our goal it to implement randomized-SVD instead of SVD, and make the process more efficient.

### How to run?


### acknowledgements
MLA implementation is based on nanoGPT implementation of Karpathy.
https://github.com/karpathy/nanoGPT