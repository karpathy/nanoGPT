_target_: configs.TrainConfig

framework: pytorch          # ML framework to use: one of 'pytorch', 'tensorflow'
backend: 'DDP'              # Backend to use for distributed training
# ds_config_path: null
device: null
port: null
seed: null
ngpus: null
precision: null
use_wandb: true
wandb_project: nanoGPT
eval_interval: 2000
log_interval: 10
eval_iters: 100
eval_only: false
always_save_checkpoint: false
init_from: scratch
max_iters: 50000
warmup_iters: 2000
dtype: bfloat16
compile: true
# defaults:
#   - _self_
#   - model: default.yaml
#   - optimizer: default.yaml
#   - logdir: default.yaml    # Defines where to run experiment using info from cfg
#   - override hydra/hydra_logging: colorlog
#   - override hydra/job_logging: custom  # colorlog
#   # - override hydra/launcher: joblib
#   # https://hydra.cc/docs/tutorials/basic/running_your_app/logging/
#   # use this to set level of only chosen command line loggers to 'DEBUG'
#   # verbose: [src.train, src.utils]
#   # - debug: true
#   # - verbose: true
# # debug: true
# hydra:
#   # verbose: true
#   job:
#     chdir: true
...

